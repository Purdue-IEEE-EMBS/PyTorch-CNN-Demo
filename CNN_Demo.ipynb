{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBS Training CNN Demo\n",
    "*Adapted from PyTorch Docs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports\n",
    "\n",
    "TODO - Import the following:\n",
    "- `torch`: Main pytorch package\n",
    "- `torchvision`: Computer vision pytorch package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO - Import torch & torchvision ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing our data\n",
    "\n",
    "We use a transformer to help us ensure consistency with our images through normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our data\n",
    "We create the following variables to store outputs for training and testing data sets:\n",
    "- `trainset`: stores the training dataset\n",
    "- `testset`: stores the test dataset\n",
    "- `trainloader`: stores a reference to the loaded training dataset\n",
    "- `testloader`: stores a reference to the loaded training dataset\n",
    "\n",
    "TODO - Complete the following:\n",
    "- store the CIFAR10 *test* dataset in `testset` (Hint: very similar to storing trainset but set the train parameter to false)\n",
    "- load the test set into trainloader (Again, similar to its training counter-part, no need to shuffle though)\n",
    "- Create a tuple called `classes` with the following class labels (strings):\n",
    "  ```\n",
    "  'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = \"\"\"TODO\"\"\"\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testloader = \"\"\"TODO\"\"\"\n",
    "\n",
    "classes = \"\"\"TODO\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the Images\n",
    "\n",
    "Let's validate that these have been loaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network\n",
    "\n",
    "TODO:\n",
    "Copy-paste your NN from the previous walk-through and modify it to take 3-channel images (R, G, B) instead of 1-channel input. (Change the first input of our first layer from 1 to 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: copy-pase your NN and modify it to accept 3-channel images ###\n",
    "\n",
    "net = Net() # Instantiating your network. Change Net() to <your-network-name>()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a loss function & optimzer\n",
    "\n",
    "These are used to assess how good or bad our network is doing and update our weights accordingly.\n",
    "\n",
    "TODOS:\n",
    "- set `criterion` to `CrossEntorypyLoss` (found in `nn`)\n",
    "- set `optimizer` to Stochastic Gradient Descent with Momentum or `SGD` (found in `optim`) with parameters `(net.parameters(), lr=0.001, momentum=0.9)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = \"\"\"TODO\"\"\"\n",
    "optimizer = \"\"\"TODO\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our network\n",
    "\n",
    "Now, we iterate over our dataset for *n* number of \"epochs\" or iterations to update the weights of our network so it can \"learn\".\n",
    "\n",
    "TODO\n",
    "1. set `num_epochs` to `5` to control the number of epochs (5 in our case)\n",
    "2. extract inputs and labels from `data` (`data` is a list of the form `[inputs, labels]`)\n",
    "3. set `outputs` equal to the result of passing `inputs` into `net()`\n",
    "4. back-propagate loss (hint: `loss` has a function called `backward()`)\n",
    "5. step stochastic gradient descent aka our optimizer (hint: `optimizer` has a function called `step()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = \"\"\"TODO 1\"\"\"\n",
    "for epoch in range(num_epochs): # iterate over the data-set num_epochs times\n",
    "\n",
    "    running_loss = 0.0 # keep track of loss for the given epoch\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs = \"\"\"TODO 2\"\"\"\n",
    "        labels = \"\"\"TODO 2\"\"\"\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = \"\"\"TODO 3\"\"\"\n",
    "        loss = criterion(outputs, labels)\n",
    "        \"\"\"TODO 4\"\"\"\n",
    "        \"\"\"TODO 5\"\"\"\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save our model\n",
    "\n",
    "Saving it to a file called `cifar_net.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Testing Data\n",
    "\n",
    "TODO:\n",
    "- Create an iterator from our testloader (use the `iter()` function and pass in the `testloader` variable we created earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = \"\"\"TODO\"\"\"\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images and labels\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model\n",
    "\n",
    "We first load our saved model and then pass in our test images. Then we extract the most likely class from the list of probablities of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH)) # load our saved model\n",
    "\n",
    "outputs = net(images) # pass in the images to our neural network\n",
    "\n",
    "probablities, predicted = torch.max(outputs, 1) # extract the most likely class\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Accuracy\n",
    "\n",
    "Lets run through each of our test images and see how our model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest probability is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # tally up the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predicted):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
